{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Inverted File Benchmark\n",
    "\n",
    "This notebook has for purpose the benchmarking of an InvertedFile. Below, we will try to evaluate the efficiency of our system by measuring :  \n",
    "  \n",
    "priority 1 :\n",
    "- the space taken on disc by an inverted file of an arbitrary size\n",
    "- the time taken on disc to read a posting list  \n",
    "\n",
    "priority 2 :\n",
    "- the time taken to write on disc an inverted file of an arbitrary size \n",
    "- the time taken to merge on disc two inverted files of an arbitrary size\n",
    "  \n",
    "Constants :  \n",
    "  \n",
    "LATIMES_PATH : string, the path to the xml files to read  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import time\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import xml.etree.ElementTree as ET\n",
    "from xml.etree.ElementTree import ParseError\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pyscripts.inverted_file import InvertedFile\n",
    "from pyscripts.formatted_document import FormattedDocument\n",
    "from pyscripts.naive_disc_interfacer import NaiveDiscInterfacer as ndi\n",
    "from pyscripts.smart_disc_interfacer import SmartDiscInterfacer as sdi\n",
    "\n",
    "LATIMES_PATH = '../latimes'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Define utilities functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def read_files(paths, n=-1):\n",
    "    \"\"\"\n",
    "    Read n files from a list of paths and convert them as xml trees. A root node <RAC> is added to every file to avoid some\n",
    "    ParseError\n",
    "    parameters :\n",
    "        - paths : enumeration of strings, a list of absolute paths where datas have to be read (datas must be xml files)\n",
    "        - n : number of files needed to be read, if -1, every possible files will be read\n",
    "    return :\n",
    "        - a list of len=(min(n, number of files) if n != -1, else number of files) of xml trees representations\n",
    "          of the documents\n",
    "    \"\"\"\n",
    "    output = []\n",
    "    for path in paths:\n",
    "        try:\n",
    "            txt = open(path, 'r').read()\n",
    "            output.append(ET.fromstring('<RAC>'+txt+'</RAC>'))\n",
    "            n -= 1\n",
    "            print('Successfully parsed document <{}>'.format(path))\n",
    "        except ParseError as e:\n",
    "            print('Can\\'t parse document <{}>. Doesn\\'t matter, skip'.format(path))\n",
    "        except IsADirectoryError:\n",
    "            print('Can\\'t parse directory <{}>. Doesn\\'t matter, skip'.format(path))\n",
    "        if n == 0:\n",
    "            return output\n",
    "    return output\n",
    "\n",
    "def score(token, document):\n",
    "    \"\"\"\n",
    "    Basic score function to make the inverted files work.\n",
    "    Doesn't have any computational interest\n",
    "    \"\"\"\n",
    "    paragraph_tokens = document['text']\n",
    "    paragraph_tokens.append(document['title'])\n",
    "    token_count = 0\n",
    "    for paragraph in paragraph_tokens:\n",
    "        for word in paragraph:\n",
    "            if word == token:\n",
    "                token_count += 1\n",
    "    return token_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Define Benchmarking functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def space_on_disc(number_of_document, interfacer):\n",
    "    \"\"\"\n",
    "    Simulate the evolution of the space taken on disc in function of the number of\n",
    "    document we put in an inverted file.\n",
    "    The simulation takes place only in the size order of small datasets, when all the inverted file can fit in memory\n",
    "    :param number_of_document : integer, how many documents should be saved on disc\n",
    "    return : integer, the size of the file (in bytes) if we would save it\n",
    "    \"\"\"\n",
    "    inverted_file = InvertedFile(score, interfacer)\n",
    "    files = glob.iglob(LATIMES_PATH + '/*')\n",
    "    xml_files = read_files(files, number_of_document)\n",
    "    for f in xml_files:\n",
    "        document = FormattedDocument(f)\n",
    "        for article in document.matches:\n",
    "            inverted_file.add_document(article)\n",
    "            \n",
    "    return len(inverted_file.get_object_as_array())\n",
    "    \n",
    "def time_to_read_posting_list(number_of_document, number_of_pl_to_read, interfacer):\n",
    "    \"\"\"\n",
    "    Simulate the reading of a posting list, in function of the approximate size of an inverted file,\n",
    "    expressed in number of document injected in.\n",
    "    The simulation takes place only in the size order of small datasets, when all the inverted file can fit in memory\n",
    "    For better precision, the posting lists are read in random order, to not false the time it takes to physically replaces \n",
    "    the lecture head.\n",
    "    :param number_of_document : integer, how many documents should be saved on disc\n",
    "    :param number_of_pl_to_read : integer, how many posting lists should be read to make the mean \n",
    "                                  (to improve computationnal speed)\n",
    "    return : integer, the mean time it takes to read a posting list of this inverted file\n",
    "    \"\"\"\n",
    "    \n",
    "    # preparing the inverted file\n",
    "    inverted_file = InvertedFile(score, interfacer)\n",
    "    files = glob.iglob(LATIMES_PATH + '/*')\n",
    "    xml_files = read_files(files, number_of_document)\n",
    "    for f in xml_files:\n",
    "        document = FormattedDocument(f)\n",
    "        for article in document.matches:\n",
    "            inverted_file.add_document(article)\n",
    "            \n",
    "    # saving inverted file on disc\n",
    "    inverted_file.save('tps.sav')\n",
    "    keys = list(inverted_file.map.keys())\n",
    "    random.shuffle(keys)\n",
    "    \n",
    "    # reading keys\n",
    "    values = []\n",
    "    inverted_file2 = InvertedFile(score, interfacer)\n",
    "    for key in keys[:number_of_pl_to_read]:\n",
    "        t_begin = time.clock()\n",
    "        inverted_file2.read_posting_lists([key], 'tps.sav')\n",
    "        values.append(time.clock() - t_begin)\n",
    "    return np.asarray(values).mean()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Define General Benchmark parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# how many files are injected in\n",
    "number_of_files = len(list(glob.iglob(LATIMES_PATH + '/*')))\n",
    "number_of_docs = np.asarray([1, 3, 6, 10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Space on disc benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "space_taken_naive = []\n",
    "space_taken_smart = []\n",
    "for n in number_of_docs:\n",
    "    cur_space= space_on_disc(n, ndi)\n",
    "    cur_space_smart = space_on_disc(n, sdi)\n",
    "    space_taken_naive.append(cur_space)\n",
    "    space_taken_smart.append(cur_space_smart)\n",
    "    print(cur_space)\n",
    "    print(cur_space_smart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Observation\n",
    "\n",
    "Between one and 10 documents saved, the weight of a document is approximately halved. Then it remains stable. The growth of the file size is linear in function of the number of documents  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# absolute space taken\n",
    "space_taken_naive = np.asarray(space_taken_naive)\n",
    "space_taken_smart = np.asarray(space_taken_smart)\n",
    "\n",
    "# relative space taken by document\n",
    "relative_unique_doc_space_naive = space_taken_naive / number_of_docs\n",
    "value_of_ref = relative_unique_doc_space_naive[0]\n",
    "relative_unique_doc_space_naive /= value_of_ref\n",
    "relative_unique_doc_space_smart = space_taken_smart / number_of_docs\n",
    "relative_unique_doc_space_smart /= value_of_ref\n",
    "\n",
    "print('display of the absolute space taken by the inverted file\\n' +\n",
    "      'in function of the number of documents injected in')\n",
    "plt.plot(number_of_docs, space_taken_naive)\n",
    "plt.plot(number_of_docs, space_taken_smart)\n",
    "plt.show()\n",
    "\n",
    "print('display of the relative space taken by document by the inverted file\\n' +\n",
    "      'in function of the number of documents injected in')\n",
    "plt.plot(number_of_docs, relative_unique_doc_space_naive)\n",
    "plt.plot(number_of_docs, relative_unique_doc_space_smart)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Time to read a posting list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_taken_naive = []\n",
    "time_taken_smart = []\n",
    "for n in number_of_docs:\n",
    "    cur_time_naive = time_to_read_posting_list(n, 50, ndi)\n",
    "    cur_time_smart = time_to_read_posting_list(n, 50, sdi)\n",
    "    print(cur_time_naive)\n",
    "    print(cur_time_smart)\n",
    "    time_taken_naive.append(cur_time_naive)\n",
    "    time_taken_smart.append(cur_time_smart)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Observation\n",
    "\n",
    "Between one and 10 documents saved, the weight of a document is approximately halved. Then it remains stable. The growth of the file size is linear in function of the number of documents because the keys are not stored in memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print('display of the time taken to read a posting list\\n' +\n",
    "      'in function of the number of documents injected in')\n",
    "naive = plt.plot(number_of_docs, time_taken_naive)\n",
    "smart = plt.plot(number_of_docs, time_taken_smart)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
